## 模拟实现 Muduo 网络库服务端功能介绍

### 程序框架认识初识

~~~c++
		client	--- | ----|						|	=> SubReactor => [read/send/...]
             			  |
		client	--- | ----|						|	=> SubReactor => [read/send/...]
						 |					  
MainReator	 =>=>=>=>=> Acceptor => | =>=>=>=>=>   |   => SubReactor => [read/send/...]
						 |
		client	--- | ----|						|	=> SubReactor => [read/send/...]
             			  |
		client	--- | ----|						|	=> SubReactor => [read/send/...]
~~~





### 运作流程大致梳理

~~~c++
用户	=> 使用 TcpServer 开发
1. 创建事件循环对象 => MainLoop
2. 创建 InetAddress 对象，封装主机 ip/port
3. 基于 TcpServer 搭建自己的服务对象类
	3.1 在 MainLoop => 构建 => TcpServer(MainLoop, InetAddress, Tcp_name);
		3.1.1 TcpServer 检查 MainLoop 合法性？
		3.1.2 创建 Acceptor 对象，就启动了监听 Acceptor::headleRead 有 accept 函数，监听连接。
		3.1.3 创建 EventLoopThreadPool 线程池对象
		3.1.4 初始化其他必要属性
	3.2 实例类中 设置 线程数量 + 定义事件回调方法 / 想要完成的任务（如：接收数据，并回显）
		3.2.1 设置 线程数量：调用 TcpServer::setThreadNum() 方法
			实际：EventLoopThreadPool::setThreadNum() 方法
		3.2.2 定义事件回调方法：调用 TcpServer::XXXCallback() 关联回调
4. 实例化自己的服务对象类，并调用 TcpServer::start() 方法
	调用 TcpServer::start() 方法后的流程：
	=> 4.1 设置 TcpServer 实体唯一限定标识，限制只有一个 TcpServer服务
	=> 4.2 调用 EventLoopThreadPool::start() 方法
		=> 通过 new EventLoopThread() 创建指定数量的 Thread 线程对象与 EventLoop 事件循环对象 
		=> 创建了 EventLoop 事件循环对象后
		=> 使用 EventLoopThread::threadFunc() 方法
			=> 先：完成 Thread 线程对象与 EventLoop 事件循环对象 的关联
			=> 再：启动事件循环 【调用了 EventLoop::loop() 方法】
				=> 方法中，调用了 Poller::poll() 方法	
					=> 在该方法中，调用了 epoll_wait() 启用了 epoll ！
					=> 1. 如果有就绪事件，就调用 fillActiveChannels() 方法向 Poller::activeChannels 成员中添加就绪事件（Channel）
					=> 2. 没有就绪事件，输出超时提示
					=> 3. 有错误，输出错误提示
	=> 4.3 建立关联并分别添加到容器管理
		=> 注：EventLoopThreadPool 上有存储工作线程和工作事件循环的容器。
	=> 4.4 TcpServer::start() -> loop_->runInLoop 启动监听
~~~







### 主要模块属性说明

~~~c++
Channel：实际就是对 fd + 关注fd上事件 + 发生事件后回调 的统一封装！
	=> [ *loop_、fd_、events_、revents_、index_、tie_、tied_、xxxCallback_ ]
    	=> loop_：所在的事件循环[线程]
    	=> fd_：关心的文件描述符	
    	=> events_：0、EPOLLIN | EPOLLPRI、EPOLLOUT
    	=> revents_：由 Poller 填写，表示就绪的事件
    	=> index_：标识了存在状态【新的(-1)、已经存在的(1)、已经删除的(2)（相对于epoll而言）】，在Poller需要使用
    	=> tie_：绑定自己：用于跨线程检测对象是否存在
    	=> tied_：标识对象是否存活
    => 总体上 Channel 对象有两个方向的实体
    	=> listenfd：处于 Acceptor【也就是新连接事件】
    	=> connedfd：处于 connection【已连接关注的事件】
    	
    	
Poller：抽象类
	=> [ *loop_、channels_{std::unordered_map<int, Channel *>} ]
        => loop_：所在的事件循环[线程]
        => channels_：是一张映射表，联系的是 fd 与 包含 fd 的 Channel 对象
        
EpollPoller：继承自 Poller，本身是封装 epoll
	=> [ epollfd_、events_{std::vector<epoll_event>} ]
    	=> epollfd_：创建的 epoll 句柄
    	=> events_：用于存储需要处理 epoll_event【其中需要 fd/ptr + 关注的事件】
    	
// Poller + EpollPoller => Demultiplex 事件分发器

// Channel 与 Poller / EpollPoller：是相互隔离（不能相互访问）的组件，需要通过 EventLoop 关联在一起
// epoll 监听的是 fd 上的 epollxxx 行为是否发生，Channel 封装了 fd 及其回调方法。
// Poller 不会直接与 Channel 发生行为，比如取监听 Channel 中的fd
// Poller 的作用就是：接收要监视的对象，反馈被监视者就绪的行为发生，通知领走即可
// 而是通过 EventLoop 作为中间键，执行操作。

// EventLoop => Reactor 反应堆

EventLoop：可以分为 两个方向：一个是 MainLoop 用于处理新连接；其他 SubLoop 用于处理就绪的 Channel 对应的回调行为
	=> [ threadId_、poller_、wakeupFd_、wakeupChannel_、activeChannels_、pendingFunctors_ ]
    	=> threadId_：记录当前 loop 对应的线程 id
    	=> poller_{std::unique_ptr<Poller>}：每一个 loop 关联一个 Poller
		=> wakeupFd_：wakeupFd_ 关联着 loop！Poller[epoll]没有事件发生时，是会阻塞的（无就绪fd就会一直等），阻塞时 loop 就是挂起的。wakeupFd_ 也是被封装成立 Channel 注册在了 loop 所对应的 Poller 上，我们可以通过向 wakeupFd_ 写东西，就相等于 wakeupFd_ 等待的内容就绪，就会触发通知机制，Poller 就会监听到动静，就会激活 关联的 loop。
		=> wakeupChannel_{std::unique_ptr<Channel>}：就是指向了 封装了 wakeupFd_ 的 Channel
		=> activeChannels_{std::vector<Channel *>}：用于存储 loop 上事件 就绪的 Channel，若存在就绪的 Channel 通过轮询算法，将 Channel 逐个分配给 SubLoop 执行任务
		=> pendingFunctors_：标识 当前 loop 中是否有需要执行的回调操作
		
		
Thread：将线程封装成对象，使用智能指针管理线程
	关键点：使用信号量来确保子线程启动成功
	=> [ started_、joined_、thread_、tid_、func_、funcName_、numCreated_ ]
    	=> started_：标识线程是否启动
    	=> joined_：标识线程处于等待
    	=> thread_{ std::shared_ptr<std::thread> }：使用智能指针管理线程，直接定义线程，会直接启动线程！
    	=> tid_：线程 id
    	=> func_：回调方法对象
    	=> funcName_：线程方法名
    	=> numCreated_{ std::atomic_int }：线程个数计数


EventLoopThread：创建线程 => 创建事件循环 => 启动事件循环 => 启动 epoll => 阻塞[被监听的fd无动静] / 反馈[被监听的fd有动静]
	注意：是先有线程，然后在线程中创建事件循环
	关键点：通过信号量来确保事件循环启动成功！
	=> [ *loop_、exiting_、thread_、callback_ ]
    	=> loop_：标识所处的 loop
    	=> exiting_：是否退出事件循环
    	=> thread_：线程对象
    	=> callback_ { std::function<void(EventLoop *)> }：线程初始的回调


EventLoopThreadPool：线程池对象，其中管理了多个线程，每个线程对应一个事件循环，因此事件管理的内容包含线程和线程对应的事件循环，实现真正的一对一。
	=> [ *baseLoop_、name_、started_、numThreads_、next_、threads_、loops_ ]
    	=> baseLoop_：主事件循环【对应主线程】
    	=> name_：主线程名
    	=> started_：线程启动状态
    	=> numThreads_：线程数量
    	=> next_：索引，用于实现轮询算法
    	=> threads_{ std::vector<std::unique_ptr<EventLoopThread>> }：管理所有线程
    	=> loops_{ std::vector<EventLoop *> }：管理所有事件的指针
    	
Socket：封装Linux系统调用套接字接口，其中包含了设置tcp连接的状态
	=> [ sockfd_ ]
    => 套接字编程操作流程
    	=> 创建套接字 => 绑定本地地址信息 => 启动 listen 监听 => accept 接收外部连接访问
    	

Acceptor：运行在主事件循环中，用于监听新的外部连接
	在 Acceptor 会创建一个套接字，就是用于监听网络连接的
	=> [ *loop_、acceptSocket_、acceptChannel_、listening_ ]
    	=> loop_：指向了主事件循环
    	=> acceptSocket_：Socket 对象
    	=> acceptChannel_：Channel 对象，接收连接后，需要把新连接用户关注的操作打包成 Channel，用于分发处理
    	=> listening_：是否处于监听状态
    	=> newConnectionCallback_：新连接的回调，在 TcpServer 中被设置
    	

Buffer：缓冲区
	=> [ buffer_、readerIndex_、writerIndex_ ]
    	=> buffer_{ std::vector<char> }：使用 vector 作为底层数据存储容器（便于根据实际场景需求扩容，便于减少内存碎片，可以反复利用）；一开始默认是 8 + 1024 字节大小
    	=> readerIndex_：标记待读取数据的起始位置
    	=> writerIndex_：标记可写入数据的起始位置
    	

TcpConnection：连接事件需要关注的操作
	=> [ loop_、name_、state_、socket_、channel_、localAddr_、peerAddr_、connectionCallback_、messageCallback_、writeComleteCallback_、highWaterMarkCallback_、closeCallback_、highWaterMark_、inputBuffer_、outputBuffer_ ]
    	=> loop_：对应 subloop
    	=> name_：	
    	=> state_：标识 Channel 对应的用户连接状态
    	=> socket_：套接字
    	=> channel_：Channel
    	=> localAddr_：本地地址信息
    	=> peerAddr_：对端（用户）地址信息
    	=> connectionCallback_：连接回调   	
    	=> messageCallback_：可读写消息回调
    	=> writeComleteCallback_：消息发送完成回调  	
    	=> highWaterMarkCallback_：高水位回调
    	=> closeCallback_：关闭回调
    	=> highWaterMark_：高水位
    	=> inputBuffer_：接收缓冲区
    	=> outputBuffer_：发送缓冲区
    	


TcpServer：
	=> [ loop_、ipPort_、name_、acceptor_、threadPool_、connectionCallback_、messageCallback_、writeComleteCallback_、threadInitCallback_、connections_ ]
    	=> loop_：关联 主事件循环
    	=> ipPort_：打包 ip和port
    	=> name_：
    	=> acceptor_：Acceptor 对象，用于监听新用户连接
    	=> threadPool_：线程池对象
    	=> connectionCallback_：连接回调
    	=> messageCallback_：有读写消息回调
    	=> writeComleteCallback_：发送完成回调
    	=> threadInitCallback_：loop 线程初始化回调
    	=> connections_ { std::unordered_map<std::string, TcpConnectionPtr> }：存储所有的连接
    	
~~~

